{
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8791720,
          "sourceType": "datasetVersion",
          "datasetId": 5285915
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariam7084/Analog-Clock/blob/main/Copy_of_cGAN_implementation_in_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is the notebook through which the fake data was generated, the run for this is in kaggle with the notebook of same name in version 2. refer that for any results. otherwise the code here is final and complete"
      ],
      "metadata": {
        "id": "4R_dzV2Y1bUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "aNP832CFBJdJ",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:36:43.19808Z",
          "iopub.execute_input": "2024-08-10T14:36:43.198544Z",
          "iopub.status.idle": "2024-08-10T14:37:03.45375Z",
          "shell.execute_reply.started": "2024-08-10T14:36:43.198511Z",
          "shell.execute_reply": "2024-08-10T14:37:03.451813Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting seed for reproducibility\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    # Set the seed for Python's built-in random module\n",
        "    random.seed(seed_value)\n",
        "\n",
        "    # Set the seed for NumPy\n",
        "    np.random.seed(seed_value)\n",
        "\n",
        "    # Set the seed for TensorFlow\n",
        "    tf.random.set_seed(seed_value)\n",
        "\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "6c55WdqcnY84",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:37:03.456742Z",
          "iopub.execute_input": "2024-08-10T14:37:03.457724Z",
          "iopub.status.idle": "2024-08-10T14:37:03.466522Z",
          "shell.execute_reply.started": "2024-08-10T14:37:03.457671Z",
          "shell.execute_reply": "2024-08-10T14:37:03.464487Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/iot-air-pollution-data/pollutionData204273.csv\")"
      ],
      "metadata": {
        "id": "wR7NmSffBfI6",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:37:03.468384Z",
          "iopub.execute_input": "2024-08-10T14:37:03.468989Z",
          "iopub.status.idle": "2024-08-10T14:37:03.587986Z",
          "shell.execute_reply.started": "2024-08-10T14:37:03.468942Z",
          "shell.execute_reply": "2024-08-10T14:37:03.586339Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "G2GCESO0Bhe5",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:37:03.59198Z",
          "iopub.execute_input": "2024-08-10T14:37:03.592563Z",
          "iopub.status.idle": "2024-08-10T14:37:03.636541Z",
          "shell.execute_reply.started": "2024-08-10T14:37:03.592517Z",
          "shell.execute_reply": "2024-08-10T14:37:03.634884Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate AQI based on WHO standards\n",
        "def calculate_aqi(concentration, breakpoints, aqi_values):\n",
        "    for i in range(len(breakpoints) - 1):\n",
        "        if breakpoints[i] <= concentration <= breakpoints[i + 1]:\n",
        "            aqi = ((aqi_values[i + 1] - aqi_values[i]) / (breakpoints[i + 1] - breakpoints[i])) * (concentration - breakpoints[i]) + aqi_values[i]\n",
        "            return aqi\n",
        "    return 0  # Return 0 if concentration is out of range\n",
        "\n",
        "# Function to calculate overall AQI for a row\n",
        "def calculate_overall_aqi(row):\n",
        "    # Placeholder WHO standards for illustration\n",
        "    ozone_breakpoints = [0, 50, 100, 150, 200, 300, 400, 500]\n",
        "    ozone_aqi_values = [0, 50, 100, 150, 200, 300, 400, 500]\n",
        "\n",
        "    pm_breakpoints = [0, 12, 35.4, 55.4, 150.4, 250.4, 350.4, 500.4]\n",
        "    pm_aqi_values = [0, 50, 100, 150, 200, 300, 400, 500]\n",
        "\n",
        "    co_breakpoints = [0, 4.4, 9.4, 12.4, 15.4, 30.4, 40.4, 50.4]\n",
        "    co_aqi_values = [0, 50, 100, 150, 200, 300, 400, 500]\n",
        "\n",
        "    so2_breakpoints = [0, 35, 75, 185, 304, 604, 804, 1004]\n",
        "    so2_aqi_values = [0, 50, 100, 150, 200, 300, 400, 500]\n",
        "\n",
        "    no2_breakpoints = [0, 53, 100, 360, 649, 1249, 1649, 2049]\n",
        "    no2_aqi_values = [0, 50, 100, 150, 200, 300, 400, 500]\n",
        "\n",
        "    # Calculate overall AQI as the maximum of individual pollutant AQI values\n",
        "    overall_aqi = max(\n",
        "        calculate_aqi(row['ozone'], ozone_breakpoints, ozone_aqi_values),\n",
        "        calculate_aqi(row['particullate_matter'], pm_breakpoints, pm_aqi_values),\n",
        "        calculate_aqi(row['carbon_monoxide'], co_breakpoints, co_aqi_values),\n",
        "        calculate_aqi(row['sulfure_dioxide'], so2_breakpoints, so2_aqi_values),\n",
        "        calculate_aqi(row['nitrogen_dioxide'], no2_breakpoints, no2_aqi_values)\n",
        "    )\n",
        "    return overall_aqi\n",
        "\n",
        "# Apply the calculate_overall_aqi function to each row to calculate the AQI\n",
        "df['AQI'] = df.apply(calculate_overall_aqi, axis=1)\n",
        "\n",
        "# Display the DataFrame with the calculated AQI\n",
        "# print(df)"
      ],
      "metadata": {
        "id": "OskJ_zfIBi7u",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:37:03.638597Z",
          "iopub.execute_input": "2024-08-10T14:37:03.638983Z",
          "iopub.status.idle": "2024-08-10T14:37:04.566684Z",
          "shell.execute_reply.started": "2024-08-10T14:37:03.638954Z",
          "shell.execute_reply": "2024-08-10T14:37:04.565366Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "AabxfQsOBnrM",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:37:04.568441Z",
          "iopub.execute_input": "2024-08-10T14:37:04.568793Z",
          "iopub.status.idle": "2024-08-10T14:37:04.591852Z",
          "shell.execute_reply.started": "2024-08-10T14:37:04.568765Z",
          "shell.execute_reply": "2024-08-10T14:37:04.589853Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ru8_-zkMNzFW",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:37:04.594637Z",
          "iopub.execute_input": "2024-08-10T14:37:04.595928Z",
          "iopub.status.idle": "2024-08-10T14:37:04.633501Z",
          "shell.execute_reply.started": "2024-08-10T14:37:04.595887Z",
          "shell.execute_reply": "2024-08-10T14:37:04.63165Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "O-sjXQZTBpdu",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:37:04.635289Z",
          "iopub.execute_input": "2024-08-10T14:37:04.635734Z",
          "iopub.status.idle": "2024-08-10T14:37:04.951039Z",
          "shell.execute_reply.started": "2024-08-10T14:37:04.635699Z",
          "shell.execute_reply": "2024-08-10T14:37:04.949268Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  conditional GAN"
      ],
      "metadata": {
        "id": "EPePKmlJBumy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and labels\n",
        "features = df[['ozone', 'particullate_matter', 'carbon_monoxide', 'sulfure_dioxide', 'nitrogen_dioxide']]\n",
        "labels = df['AQI']"
      ],
      "metadata": {
        "id": "jZMNAM5KBtAQ",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:37:04.952714Z",
          "iopub.execute_input": "2024-08-10T14:37:04.953443Z",
          "iopub.status.idle": "2024-08-10T14:37:04.963067Z",
          "shell.execute_reply.started": "2024-08-10T14:37:04.953384Z",
          "shell.execute_reply": "2024-08-10T14:37:04.961655Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize features\n",
        "# features = (features - features.min()) / (features.max() - features.min())\n",
        "\n",
        "# Split the dataset into training and test splits\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "wMe9PhkVD2oD",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:37:04.966872Z",
          "iopub.execute_input": "2024-08-10T14:37:04.967324Z",
          "iopub.status.idle": "2024-08-10T14:37:04.985821Z",
          "shell.execute_reply.started": "2024-08-10T14:37:04.967289Z",
          "shell.execute_reply": "2024-08-10T14:37:04.984361Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "latent_dim = 100  # Size of the random noise vector\n",
        "num_features = len(features.columns)\n",
        "\n",
        "# Build the generator model\n",
        "generator = keras.Sequential([\n",
        "    layers.Input(shape=(latent_dim + 1,)),  # Additional input for the label\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(num_features, activation='linear') # change activation to ReLu or sigmoid and then train again from linear\n",
        "])\n",
        "\n",
        "# Build the discriminator model\n",
        "discriminator = keras.Sequential([\n",
        "    layers.Input(shape=(num_features + 1,)),  # Additional input for the label\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Using sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the discriminator model\n",
        "discriminator.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "                      loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Build and compile the CGAN model\n",
        "z = layers.Input(shape=(latent_dim,))\n",
        "label = layers.Input(shape=(1,), dtype='float32')\n",
        "concatenated_gen = layers.concatenate([z, label])\n",
        "\n",
        "fake_data = generator(concatenated_gen)\n",
        "concatenated_disc = layers.concatenate([fake_data, label])\n",
        "\n",
        "validity = discriminator(concatenated_disc)\n",
        "\n",
        "cgan = keras.Model(inputs=[z, label], outputs=validity)\n",
        "\n",
        "# Compile the CGAN model after compiling the generator and discriminator\n",
        "cgan.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "             loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the CGAN\n",
        "epochs = 1000\n",
        "batch_size = 64\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Generate random noise and random labels\n",
        "    noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
        "    random_labels = np.random.uniform(0, 1, size=(batch_size, 1))  # Generate random float labels\n",
        "\n",
        "    # Generate fake samples with the generator\n",
        "    generated_data = generator.predict(np.concatenate([noise, random_labels], axis=1))\n",
        "\n",
        "    # Sample real data\n",
        "    real_samples_indices = np.random.randint(0, features_train.shape[0], batch_size)\n",
        "    real_samples = features_train.iloc[real_samples_indices].values\n",
        "    real_labels = labels_train.iloc[real_samples_indices].values.reshape(-1, 1)\n",
        "\n",
        "    # Train the discriminator\n",
        "    d_loss_real = discriminator.train_on_batch(np.concatenate([real_samples, real_labels], axis=1), np.ones((batch_size, 1)))\n",
        "    d_loss_fake = discriminator.train_on_batch(np.concatenate([generated_data, random_labels], axis=1), np.zeros((batch_size, 1)))\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train the generator (via the CGAN model)\n",
        "    noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
        "    random_labels = np.random.uniform(0, 1, size=(batch_size, 1))  # Generate random float labels\n",
        "    labels_gan = np.ones((batch_size, 1))  # Labels for the generator are set to be real\n",
        "    g_loss = cgan.train_on_batch([noise, random_labels], labels_gan)\n",
        "\n",
        "    # Print progress\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, D Loss: {d_loss[0]}, D Accuracy: {d_loss[1]}, G Loss: {g_loss[0]}\")\n"
      ],
      "metadata": {
        "id": "u1kSOL7SFKC8",
        "execution": {
          "iopub.status.busy": "2024-08-10T14:37:04.987712Z",
          "iopub.execute_input": "2024-08-10T14:37:04.988365Z",
          "iopub.status.idle": "2024-08-10T15:01:17.182664Z",
          "shell.execute_reply.started": "2024-08-10T14:37:04.988329Z",
          "shell.execute_reply": "2024-08-10T15:01:17.181403Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the final metrics after training\n",
        "\n",
        "print('Final Training Results')\n",
        "print('---'*20)\n",
        "print(f\"Discriminator Loss: {d_loss[0]}\")\n",
        "print(f\"Discriminator Accuracy: {d_loss[1]}\")\n",
        "print(f\"Generator Loss: {g_loss[0]}\")\n"
      ],
      "metadata": {
        "id": "ZlS1CWaXlrx_",
        "execution": {
          "iopub.status.busy": "2024-08-10T15:03:32.410562Z",
          "iopub.execute_input": "2024-08-10T15:03:32.411087Z",
          "iopub.status.idle": "2024-08-10T15:03:32.419441Z",
          "shell.execute_reply.started": "2024-08-10T15:03:32.411049Z",
          "shell.execute_reply": "2024-08-10T15:03:32.417595Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, evaluate the generator on the test set\n",
        "noise_test = np.random.normal(0, 1, size=(features_test.shape[0], latent_dim))\n",
        "random_labels_test = np.random.uniform(0, 1, size=(features_test.shape[0], 1))\n",
        "generated_data_test = generator.predict(np.concatenate([noise_test, random_labels_test], axis=1))\n"
      ],
      "metadata": {
        "id": "6Yux59qQFVdw",
        "execution": {
          "iopub.status.busy": "2024-08-10T15:03:41.610613Z",
          "iopub.execute_input": "2024-08-10T15:03:41.6111Z",
          "iopub.status.idle": "2024-08-10T15:03:42.119836Z",
          "shell.execute_reply.started": "2024-08-10T15:03:41.611063Z",
          "shell.execute_reply": "2024-08-10T15:03:42.11838Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking and printing the results on the test set\n",
        "\n",
        "# Evaluate the generator on the test set\n",
        "real_samples_test = features_test.values\n",
        "real_labels_test = labels_test.values.reshape(-1, 1)\n",
        "\n",
        "# Calculate the performance of the discriminator on the test set\n",
        "d_loss_real_test = discriminator.evaluate(np.concatenate([real_samples_test, real_labels_test], axis=1), np.ones((features_test.shape[0], 1)), verbose=0)\n",
        "d_loss_fake_test = discriminator.evaluate(np.concatenate([generated_data_test, random_labels_test], axis=1), np.zeros((features_test.shape[0], 1)), verbose=0)\n",
        "\n",
        "print(f\"Test Set - Discriminator Real Loss: {d_loss_real_test[0]}, Discriminator Real Accuracy: {d_loss_real_test[1]}\")\n",
        "print(f\"Test Set - Discriminator Fake Loss: {d_loss_fake_test[0]}, Discriminator Fake Accuracy: {d_loss_fake_test[1]}\")\n",
        "\n",
        "# Optionally calculate the generator's performance by evaluating how well it fools the discriminator\n",
        "g_loss_test = cgan.evaluate([noise_test, random_labels_test], np.ones((features_test.shape[0], 1)), verbose=0)\n",
        "print(f\"Test Set - Generator Loss: {g_loss_test[0]}\")\n"
      ],
      "metadata": {
        "id": "DorZFWt6l3EA",
        "execution": {
          "iopub.status.busy": "2024-08-10T15:03:47.06498Z",
          "iopub.execute_input": "2024-08-10T15:03:47.065505Z",
          "iopub.status.idle": "2024-08-10T15:03:48.638578Z",
          "shell.execute_reply.started": "2024-08-10T15:03:47.065467Z",
          "shell.execute_reply": "2024-08-10T15:03:48.63687Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generating the fake data\n"
      ],
      "metadata": {
        "id": "m9UsA2kamgKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of samples to generate\n",
        "num_samples = 10000\n",
        "\n",
        "# Generate random noise and random labels\n",
        "noise_gen = np.random.normal(0, 1, size=(num_samples, latent_dim))\n",
        "random_labels_gen = np.random.uniform(0, 1, size=(num_samples, 1))\n",
        "\n",
        "# Generate fake data using the generator\n",
        "generated_data_gen = generator.predict(np.concatenate([noise_gen, random_labels_gen], axis=1))\n",
        "\n",
        "# Create a DataFrame to store the generated data\n",
        "generated_df = pd.DataFrame(generated_data_gen, columns=features.columns)\n",
        "\n",
        "# Add the labels to the DataFrame\n",
        "generated_df['AQI'] = random_labels_gen\n",
        "\n",
        "# Display the first few rows of the generated DataFrame\n",
        "print(generated_df.head())\n"
      ],
      "metadata": {
        "id": "aAFEzTiKwix_",
        "execution": {
          "iopub.status.busy": "2024-08-10T15:03:54.551217Z",
          "iopub.execute_input": "2024-08-10T15:03:54.551767Z",
          "iopub.status.idle": "2024-08-10T15:03:55.71485Z",
          "shell.execute_reply.started": "2024-08-10T15:03:54.55173Z",
          "shell.execute_reply": "2024-08-10T15:03:55.713602Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### generating unnormalized data"
      ],
      "metadata": {
        "id": "YMCQK_J709SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of samples to generate\n",
        "num_samples = 10000\n",
        "\n",
        "# Generate random noise and random labels\n",
        "noise_gen = np.random.normal(0, 1, size=(num_samples, latent_dim))\n",
        "random_labels_gen = np.random.uniform(0, 1, size=(num_samples, 1))\n",
        "\n",
        "# Generate fake data using the generator\n",
        "generated_data_gen = generator.predict(np.concatenate([noise_gen, random_labels_gen], axis=1))\n",
        "\n",
        "# Reverse the normalization process\n",
        "# Assuming the original features were normalized as: (features - min) / (max - min)\n",
        "features_min = df[['ozone', 'particullate_matter', 'carbon_monoxide', 'sulfure_dioxide', 'nitrogen_dioxide']].min()\n",
        "features_max = df[['ozone', 'particullate_matter', 'carbon_monoxide', 'sulfure_dioxide', 'nitrogen_dioxide']].max()\n",
        "\n",
        "# Unnormalize the generated data\n",
        "generated_data_unnorm = generated_data_gen * (features_max.values - features_min.values) + features_min.values\n",
        "\n",
        "# Create a DataFrame to store the unnormalized generated data\n",
        "generated_df_unnorm = pd.DataFrame(generated_data_unnorm, columns=features.columns)\n",
        "\n",
        "# Since the labels were not normalized, we can directly assign the random_labels_gen\n",
        "generated_df_unnorm['AQI'] = random_labels_gen\n",
        "\n",
        "# Display the first few rows of the unnormalized generated DataFrame\n",
        "print(generated_df_unnorm.head())\n",
        "\n",
        "# Save the unnormalized generated data to a file if needed\n",
        "# generated_df_unnorm.to_csv('generated_data_unnormalized.csv', index=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T15:04:09.296026Z",
          "iopub.execute_input": "2024-08-10T15:04:09.296486Z",
          "iopub.status.idle": "2024-08-10T15:04:10.33128Z",
          "shell.execute_reply.started": "2024-08-10T15:04:09.296451Z",
          "shell.execute_reply": "2024-08-10T15:04:10.329352Z"
        },
        "trusted": true,
        "id": "yQQuLpVO09SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the generated data to a csv file\n",
        "generated_df.to_csv('generated_data.csv', index=False)"
      ],
      "metadata": {
        "id": "gAVjTMYmoLmf",
        "execution": {
          "iopub.status.busy": "2024-08-10T15:04:55.166449Z",
          "iopub.execute_input": "2024-08-10T15:04:55.166928Z",
          "iopub.status.idle": "2024-08-10T15:04:55.295511Z",
          "shell.execute_reply.started": "2024-08-10T15:04:55.16689Z",
          "shell.execute_reply": "2024-08-10T15:04:55.294092Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "65TyvHV809SG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}